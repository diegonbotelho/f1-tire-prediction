{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/home/mgasilva/code/diegonbotelho/f1-tire-prediction/raw_data/df_all_races.csv'\n",
    "all_races_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_races_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "all_races_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"Dataset shape:\", all_races_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data Analysis\n",
    "print(\"Missing data per column:\")\n",
    "print(all_races_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusion of features that are not necessary\n",
    "columns_to_remove = [\n",
    "    'Time',\n",
    "    'DriverNumber',\n",
    "    'PitOutTime',\n",
    "    'PitInTime',\n",
    "    'Sector1SessionTime',\n",
    "    'Sector2SessionTime',\n",
    "    'Sector3SessionTime',\n",
    "    'SpeedI1',\n",
    "    'SpeedI2',\n",
    "    'SpeedFL',\n",
    "    'SpeedST',\n",
    "    'IsPersonalBest',\n",
    "    'FreshTyre',\n",
    "    'Team',\n",
    "    'LapStartTime',\n",
    "    'LapStartDate',\n",
    "    'Deleted',\n",
    "    'DeletedReason',\n",
    "    'FastF1Generated',\n",
    "    'IsAccurate',\n",
    "    'WindDirection',\n",
    "    'WindSpeed',\n",
    "    'Delta_Lap'\n",
    "]\n",
    "\n",
    "new_df = all_races_df.drop(columns=columns_to_remove)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"Dataset shape:\", new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data Analysis\n",
    "print(\"Missing data per column:\")\n",
    "print(new_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna(subset=['Position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data Analysis\n",
    "print(\"Missing data per column:\")\n",
    "print(new_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify duplicates\n",
    "print(\"\\nNumber of duplicates:\")\n",
    "print(new_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy for missing values\n",
    "\n",
    "# Fill null values in numeric columns with the median\n",
    "numerical_columns = new_df.select_dtypes(include=[np.number]).columns\n",
    "new_df.loc[:, numerical_columns] = new_df[numerical_columns].fillna(new_df[numerical_columns].median())\n",
    "\n",
    "# Verify missing values after treatment\n",
    "print(\"\\nMissing values after treatment:\")\n",
    "print(new_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Compound'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "numerical_features = [\n",
    "    'LapTime',            # Lap time in seconds\n",
    "    'TyreLife',           # Tyre life\n",
    "    'AirTemp',            # Air temperature\n",
    "    'TrackTemp',          # Track temperature\n",
    "    'WindSpeed',          # Wind speed\n",
    "    'SpeedI1',            # Speed in the first sector\n",
    "    'SpeedI2',            # Speed in the second sector\n",
    "    'SpeedFL',            # Speed on the main straight\n",
    "    'SpeedST',            # Speed in the timing sector\n",
    "    'Position',           # Position in the race\n",
    "    'Humidity',           # Relative humidity of the air\n",
    "    'Pressure',           # Atmospheric pressure\n",
    "    'WindDirection',      # Wind direction\n",
    "    'Sector1Time',        # Time in sector 1\n",
    "    'Sector2Time',        # Time in sector 2\n",
    "    'Sector3Time',        # Time in sector 3\n",
    "    'LapNumber',          # Number of the lap\n",
    "    'Delta_Lap'           # time difference between two consecutives laps for each pilot\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "categorical_features = [\n",
    "    'Compound',    # Tire type (SOFT, MEDIUM, HARD)\n",
    "    'TrackStatus', # Track status (green flag, yellow flag, etc.)\n",
    "    'FreshTyre',   # True or false\n",
    "    'Rainfall'     # True or false\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outliers from LapTime\n",
    "\n",
    "# Calculate Q1 and Q3\n",
    "Q1 = new_df['LapTime'].quantile(0.25)\n",
    "Q3 = new_df['LapTime'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define boundaries for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "new_df = new_df[(new_df['LapTime'] >= lower_bound) & (new_df['LapTime'] <= upper_bound)]\n",
    "\n",
    "new_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Outliers from Pressure\n",
    "\n",
    "# # Calculate Q1 and Q3\n",
    "# Q1 = new_df['Pressure'].quantile(0.25)\n",
    "# Q3 = new_df['Pressure'].quantile(0.75)\n",
    "\n",
    "# # Calculate the IQR\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# # Define boundaries for outliers\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# # Filter out outliers\n",
    "# new_df = new_df[(new_df['Pressure'] >= lower_bound) & (new_df['Pressure'] <= upper_bound)]\n",
    "\n",
    "# new_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, calculate the max lap number for each unique GrandPrix/Event_Year combination\n",
    "new_df['LapPct'] = new_df['LapNumber'] / new_df.groupby(['Event_Year', 'GrandPrix'])['LapNumber'].transform('max')\n",
    "\n",
    "# Display a sample\n",
    "new_df[['Driver','LapNumber','LapPct','Event_Year','GrandPrix']].head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to save a copy of the dataframe for the one-hot encoder at this point\n",
    "\n",
    "new_df_copy = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Colummns for Robust Scaler\n",
    "# columns_for_robust_scaler = ['LapTime',\n",
    "#                              'TyreLife',\n",
    "#                              'AirTemp',\n",
    "#                              'TrackTemp',\n",
    "#                              'Humidity',\n",
    "#                              'Pressure',\n",
    "#                              'Sector1Time',\n",
    "#                              'Sector2Time',\n",
    "#                              'Sector3Time']\n",
    "\n",
    "# # Colummns for MinMax Scaler\n",
    "# columns_for_minmax_scaler = ['Position', 'LapNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_pipeline = Pipeline([\n",
    "    ('Median_Imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('Robust_Scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_pipeline = Pipeline([\n",
    "    ('Median_Imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('Minmax_Scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_pipeline = Pipeline([\n",
    "    ('Median_imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('Standard_Scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_pipeline = Pipeline([\n",
    "    ('Median_imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    ('minmax_scaler', MinMaxScaler(feature_range=(-1, 1)))  # Customize range here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessor = ColumnTransformer([\n",
    "    ('robust_transformer', distribution_pipeline, ['LapTime',\n",
    "                                                     'AirTemp',\n",
    "                                                     'TrackTemp',\n",
    "                                                     'Humidity']),\n",
    "    ('range_transformer', range_pipeline, ['Position', 'Stint', 'TyreLife']),\n",
    "    ('robust_and_scale', scaling_pipeline, ['Pressure', 'Sector1Time', 'Sector2Time', 'Sector3Time']),\n",
    "    ('passthrough_cols', 'passthrough', ['LapPct'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = numeric_preprocessor.fit_transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(transformed_df, columns = numeric_preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encode features (OneHotEnconder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_encodable_features = ['Driver', 'GrandPrix', 'Compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_copy = new_df_copy[categoric_encodable_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(new_df_copy[['Driver']])\n",
    "\n",
    "new_df_copy[ohe.get_feature_names_out()] = ohe.transform(new_df_copy[['Driver']])\n",
    "\n",
    "new_df_copy = new_df_copy.drop(columns=[\"Driver\"])\n",
    "new_df_copy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(new_df_copy[['GrandPrix']])\n",
    "\n",
    "new_df_copy[ohe.get_feature_names_out()] = ohe.transform(new_df_copy[['GrandPrix']])\n",
    "\n",
    "new_df_copy = new_df_copy.drop(columns=[\"GrandPrix\"])\n",
    "new_df_copy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(new_df_copy[['Compound']])\n",
    "\n",
    "new_df_copy[ohe.get_feature_names_out()] = ohe.transform(new_df_copy[['Compound']])\n",
    "\n",
    "new_df_copy = new_df_copy.drop(columns=[\"Compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_copy.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([new_df, new_df_copy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
